ptfs262h@a0704:~/gpu$ nsys profile --stats=true --trace=cuda,nvtx ./MDBench-CP-auto-NVCC-X86-SP
WARNING: Device-side CUDA Event completion trace is currently enabled.
         This may increase runtime overhead and the likelihood of false
         dependencies across CUDA Streams. If you wish to avoid this, please
         disable the feature with --cuda-event-trace=false.
Collecting data...
Using temporary file: /tmp/3074961.alex/atoms_tmp.txt
Parameters:
        Force field: lj
        Kernel: GPU, MxN: 8x8, Vector width: 8
        SIMD Intrinsics: CUDA
        Super-clustering: yes
        Data layout: AoS
        Floating-point precision: single
        Unit cells (nx, ny, nz): 32, 32, 32
        Domain box sizes (x, y, z): 5.374708e+01, 5.374708e+01, 5.374708e+01
        Periodic (x, y, z): 1, 1, 1
        Lattice size: 1.679596e+00
        Epsilon: 1.000000e+00
        Sigma: 1.000000e+00
        Temperature: 1.440000e+00
        RHO: 8.442000e-01
        Mass: 1.000000e+00
        Number of types: 4
        Number of timesteps: 200
        Report stats every (timesteps): 100
        Reneighbor every (timesteps): 20
        Sort atoms: no
        Single atom type: false
        Prune every (timesteps): 1000
        Output positions every (timesteps): 20
        Output velocities every (timesteps): 5
        Delta time (dt): 5.000000e-03
        Cutoff radius: 2.500000e+00
        Skin: 3.000000e-01
        Half neighbor lists: 0
        Processor frequency (GHz): 2.4000
----------------------------------------------------------------------------
step    temp            pressure
0       1.440001e+00    1.215639e+00
100     8.114808e-01    6.850469e-01
200     7.857338e-01    6.633114e-01
----------------------------------------------------------------------------
System: 131072 atoms 68290 ghost atoms, Steps: 200
TOTAL 1.55s

    | FORCE | NEIGH |BALANCE|FORWARD|REVERSE| UPDATE|  REST |  SETUP|
----|-------|-------|-------|-------|-------|-------|-------|-------|
 AVG|   0.08|   1.29|   0.00|   0.00|   0.00|   0.01|   0.19|   0.59|
 MIN|   0.08|   1.29|   0.00|   0.00|   0.00|   0.01|   0.19|   0.59|
 MAX|   0.08|   1.29|   0.00|   0.00|   0.00|   0.01|   0.19|   0.59|
----------------------------------------------------------------------------
Performance: 16.86 million atom updates per second
Generating '/tmp/3074961.alex/nsys-report-5ad1.qdstrm'
[1/7] [========================100%] report7.nsys-rep
[2/7] [========================100%] report7.sqlite
[3/7] Executing 'nvtx_sum' stats report
SKIPPED: /home/hpc/ptfs/ptfs262h/gpu/report7.sqlite does not contain NV Tools Extension (NVTX) data.
[4/7] Executing 'cuda_api_sum' stats report

 Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)   Max (ns)   StdDev (ns)           Name         
 --------  ---------------  ---------  -----------  ---------  --------  ----------  -----------  ----------------------
     65.7      175,466,341        146  1,201,824.3   23,857.0     9,940  14,017,742  2,546,272.1  cudaMemcpy            
     31.1       82,988,654        791    104,916.1   14,759.0    11,764     405,375    156,598.2  cudaDeviceSynchronize 
      1.2        3,183,421        791      4,024.6    3,226.0     2,996     233,093     10,372.5  cudaLaunchKernel      
      0.9        2,291,627         12    190,968.9  143,410.0    12,905     502,007    124,815.5  cudaFree              
      0.8        2,229,958         15    148,663.9  169,707.0     4,088     229,947     76,670.1  cudaMalloc            
      0.4          959,400        201      4,773.1    3,677.0     3,276      40,851      4,572.6  cudaMemset            
      0.0           14,449          1     14,449.0   14,449.0    14,449      14,449          0.0  cuCtxSynchronize      
      0.0            3,317          1      3,317.0    3,317.0     3,317       3,317          0.0  cudaDeviceReset       
      0.0              731          1        731.0      731.0       731         731          0.0  cuModuleGetLoadingMode

[5/7] Executing 'cuda_gpu_kern_sum' stats report

 Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                                                Name                                              
 --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ------------------------------------------------------------------------------------------------
     93.4       63,812,062        201  317,472.9  315,902.0   307,967   332,414      5,543.2  computeForceLJCudaSup_warp(float *, float *, int, int *, int *, int, int, float, float, float)  
      2.7        1,829,046        190    9,626.6    9,600.0     9,312    10,112        160.0  cudaUpdatePbcSup_warp(float *, int *, int *, int *, int *, int *, int, int, float, float, float)
      2.0        1,351,317        200    6,756.6    6,720.0     6,368     7,872        209.3  cudaInitialIntegrateSup_warp(float *, float *, float *, int, float, float)                      
      2.0        1,333,467        200    6,667.3    6,656.0     6,528     6,912         65.2  cudaFinalIntegrateSup_warp(float *, float *, int, float)                                        

[6/7] Executing 'cuda_gpu_mem_time_sum' stats report

 Time (%)  Total Time (ns)  Count   Avg (ns)     Med (ns)    Min (ns)    Max (ns)   StdDev (ns)           Operation          
 --------  ---------------  -----  -----------  -----------  ---------  ----------  -----------  ----------------------------
     82.7      148,428,098     22  6,746,731.7  6,093,915.0  6,047,068  13,438,639  2,083,410.8  [CUDA memcpy Device-to-Host]
     11.6       20,754,621    124    167,376.0      5,120.0      1,312   2,018,131    298,288.8  [CUDA memcpy Host-to-Device]
      5.7       10,247,874    201     50,984.4     50,943.0     50,463      52,736        281.7  [CUDA memset]               

[7/7] Executing 'cuda_gpu_mem_size_sum' stats report

 Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          
 ----------  -----  --------  --------  --------  --------  -----------  ----------------------------
 15,436.800    201    76.800    76.800    76.800    76.800        0.000  [CUDA memset]               
  1,689.600     22    76.800    76.800    76.800    76.800        0.000  [CUDA memcpy Device-to-Host]
    289.007    124     2.331     0.035     0.000     8.302        3.387  [CUDA memcpy Host-to-Device]
